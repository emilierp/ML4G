# Day 1 

https://einops.rocks/1-einops-basics/

https://einops.rocks/2-einops-for-deep-learning/

- PyTorch Exercise (w0d1 mlab)

- Einops (rearrange, reduce, repeat), Torch (arange, einsum, as_strided), Indexing (integer based, torch.gather)

- ReLU, Batched Log-Softmax, Log-CrossEntropy loss, LogSumExp, Sample distribution

## Day 2

ResNet https://arxiv.org/pdf/1512.03385.pdf

Batch Normalization in Convolutional Neural Networks  https://www.baeldung.com/cs/batch-normalization-cnn

- ResNet : Data preparation (troch.Transforms, Compose), Predictions (model.eval(), with torch.inference_mode(), softmax, topk)

- Practises with einsum and as_strided

- Functions (Convolution, Padding, Stride, MaxPooling), Modules (Convolution, Linear, Pooling, Batch Normalization)


## Day 3 

- Binary Classification and training loop with hyperparameter tuning

- Adversarial attacks
